{
  "approved_at_utc": null,
  "subreddit": "ripred",
  "selftext": "## Example: Tic-Tac-Toe AI Implementation \n\nTo illustrate the library in action, we present a simplified Tic-Tac-Toe AI that uses our minimax library. This example will also serve as a template for other games.\n\n**Game Setup:** Tic-Tac-Toe is a 3x3 grid game where players alternate placing their symbol (X or O). We\u2019ll assume the AI plays \u201cX\u201d and the human \u201cO\u201d for evaluation purposes (it doesn't actually matter which is which as long as evaluation is consistent). The entire game tree has at most 9! = 362880 possible games, but we can search it exhaustively easily. We will still use alpha-beta for demonstration, though it\u2019s actually not needed to solve tic-tac-toe (the state space is small). Our AI will always either win or draw, as tic-tac-toe is a solved game where a perfect player never loses.\n\n**TicTacToeGame Class:** (As partially shown earlier)\n\n```cpp\n#include &lt;MinimaxAI.h&gt;\n\nenum Player { HUMAN = 0, AI = 1 };\n\nclass TicTacToeGame : public GameInterface {\npublic:\n    uint8_t board[9];\n    Player current;\n    TicTacToeGame() {\n        memset(board, 0, 9);\n        current = AI;  // let AI go first for example\n    }\n    // Evaluate board from AI's perspective\n    int evaluateBoard() override {\n        if (isWinner(1)) return +10;       // AI (X) wins\n        if (isWinner(2)) return -10;       // Human (O) wins\n        return 0;  // draw or non-final state (could add heuristics here)\n    }\n    // Generate all possible moves (empty cells)\n    uint8_t generateMoves(Move *moves) override {\n        uint8_t count = 0;\n        for (uint8_t i = 0; i &lt; 9; ++i) {\n            if (board[i] == 0) {           // 0 means empty\n                moves[count].from = i;     // 'from' not used, but set to i for clarity\n                moves[count].to   = i;\n                count++;\n            }\n        }\n        return count;\n    }\n    // Apply move: place current player's mark\n    void applyMove(const Move &amp;m) override {\n        uint8_t pos = m.to;\n        board[pos] = (current == AI ? 1 : 2);\n        current    = (current == AI ? HUMAN : AI);\n    }\n    // Undo move: remove mark\n    void undoMove(const Move &amp;m) override {\n        uint8_t pos = m.to;\n        board[pos] = 0;\n        current    = (current == AI ? HUMAN : AI);\n    }\n    bool isGameOver() override {\n        return isWinner(1) || isWinner(2) || isBoardFull();\n    }\n    int currentPlayer() override {\n        // Return +1 if it's AI's turn (maximizing), -1 if Human's turn\n        return (current == AI ? 1 : -1);\n    }\nprivate:\n    bool isBoardFull() {\n        for (uint8_t i = 0; i &lt; 9; ++i) {\n            if (board[i] == 0) return false;\n        }\n        return true;\n    }\n    bool isWinner(uint8_t mark) {\n        // Check all win conditions for mark (1 or 2)\n        const uint8_t wins[8][3] = {\n            {0,1,2}, {3,4,5}, {6,7,8},   // rows\n            {0,3,6}, {1,4,7}, {2,5,8},   // cols\n            {0,4,8}, {2,4,6}             // diagonals\n        };\n        for (auto &amp;w : wins) {\n            if (board[w[0]] == mark &amp;&amp; board[w[1]] == mark &amp;&amp; board[w[2]] == mark)\n                return true;\n        }\n        return false;\n    }\n};\n\n```\n\nA few notes on this implementation:\n\n-   We used `1` to represent AI\u2019s mark (X) and `2` for human (O). Initially, we set `current = AI` (so AI goes first). This is just for demonstration; one could easily start with human first.\n-   The evaluation returns +10 for a win by AI, -10 for a win by the human, and 0 otherwise. This simplistic evaluation is sufficient because the search will go to terminal states (we set depth=9 so it can reach endgames). If we were limiting depth, we could add heuristic values for \u201ctwo in a row\u201d etc. to guide the AI.\n-   `generateMoves` returns all empty positions. We don\u2019t do any special ordering here, but we could, for example, check if any move is a winning move and put it first (in tic-tac-toe, a simple heuristic: center (index 4) is often best to try first, corners next, edges last).\n-   `applyMove` and `undoMove` are straightforward. Because tic-tac-toe is so simple, we didn\u2019t need to store additional info for undo (the move itself knows the position, and we know what was there before \u2013 empty).\n-   `currentPlayer()` returns +1 or -1 to indicate who\u2019s turn it is. In our `MinimaxAI` implementation, we might not even need to call this if we manage a bool, but it\u2019s available for completeness or if the evaluation function needed to know whose turn (some games might incorporate whose turn it is into evaluation).\n\n**Minimax Solver Implementation:** With the game class defined, our solver can be implemented. Here\u2019s a conceptual snippet of how `MinimaxAI` might look (non-templated version using interface pointers):\n\n```cpp\nclass MinimaxAI {\npublic:\n    GameInterface *game;\n    uint8_t maxDepth;\n    Move bestMove;  // stores result of last search\n    \n    MinimaxAI(GameInterface &amp;gameRef, uint8_t depth)\n        : game(&amp;gameRef), maxDepth(depth) {}\n    \n    // Public function to get best move\n    Move findBestMove() {\n        // We assume game-&gt;currentPlayer() tells us if this is maximizing player's turn.\n        bool maximizing = (game-&gt;currentPlayer() &gt; 0);\n        int alpha = -32767;  // -INF\n        int beta  =  32767;  // +INF\n        bestMove = Move();   // reset\n        int bestVal = (maximizing ? -32767 : 32767);\n        \n        Move moves[MAX_MOVES];\n        uint8_t moveCount = game-&gt;generateMoves(moves);\n        \n        for (uint8_t i = 0; i &lt; moveCount; ++i) {\n            game-&gt;applyMove(moves[i]);\n            int eval = minimaxRecursive(maxDepth - 1, alpha, beta, !maximizing);\n            game-&gt;undoMove(moves[i]);\n            \n            if (maximizing) {\n                if (eval &gt; bestVal) {\n                    bestVal = eval;\n                    bestMove = moves[i];\n                }\n                alpha = max(alpha, eval);\n            } else {\n                if (eval &lt; bestVal) {\n                    bestVal = eval;\n                    bestMove = moves[i];\n                }\n                beta = min(beta, eval);\n            }\n            if (alpha &gt;= beta) {\n                // prune remaining moves at root (though rare to prune at root)\n                break;\n            }\n        }\n        return bestMove;\n    }\n    \nprivate:\n    int minimaxRecursive(uint8_t depth, int alpha, int beta, bool maximizing) {\n        if (depth == 0 || game-&gt;isGameOver()) {\n            return game-&gt;evaluateBoard();\n        }\n        Move moves[MAX_MOVES];\n        uint8_t moveCount = game-&gt;generateMoves(moves);\n        if (maximizing) {\n            int maxScore = -32767;\n            for (uint8_t i = 0; i &lt; moveCount; ++i) {\n                game-&gt;applyMove(moves[i]);\n                int score = minimaxRecursive(depth - 1, alpha, beta, false);\n                game-&gt;undoMove(moves[i]);\n                if (score &gt; maxScore) {\n                    maxScore = score;\n                }\n                if (score &gt; alpha) {\n                    alpha = score;\n                }\n                if (alpha &gt;= beta) break;  // cut-off\n            }\n            return maxScore;\n        } else {\n            int minScore = 32767;\n            for (uint8_t i = 0; i &lt; moveCount; ++i) {\n                game-&gt;applyMove(moves[i]);\n                int score = minimaxRecursive(depth - 1, alpha, beta, true);\n                game-&gt;undoMove(moves[i]);\n                if (score &lt; minScore) {\n                    minScore = score;\n                }\n                if (score &lt; beta) {\n                    beta = score;\n                }\n                if (alpha &gt;= beta) break;  // cut-off\n            }\n            return minScore;\n        }\n    }\n};\n\n```\n\n_(Note: In actual implementation, we would likely define `INF` as a large sentinel value like `INT16_MAX` since we use `int` for scores, and ensure evaluateBoard never returns something beyond those bounds. Here 32767 is used as a stand-in for +\u221e.)_\n\nThis code demonstrates the core logic:\n\n-   `findBestMove()` handles the top-level iteration over moves and chooses the best one.\n-   `minimaxRecursive()` is the depth-first search with alpha-beta. It directly uses the game interface methods for moves and evaluation.\n-   We used `game-&gt;currentPlayer()` to decide if the root call is maximizing or not. In our tic-tac-toe game, that returns +1 if AI\u2019s turn (maximizing) or -1 if human\u2019s turn (minimizing). This ensures the algorithm\u2019s perspective aligns with the evaluation function\u2019s scoring (since `evaluateBoard` was written from AI perspective, we must maximize on AI\u2019s turns).\n-   The algorithm updates `alpha` and `beta` appropriately and prunes when possible. Pruning at the root is rare because we want the best move even if others are worse, but the code still handles it.\n\n**Example Sketch (`TicTacToeAI.ino`):**\n\nFinally, here is how a simple loop might look in the Arduino sketch to play tic-tac-toe via Serial:\n\n```cpp\n#include &lt;MinimaxAI.h&gt;\nTicTacToeGame game;\nMinimaxAI ai(game, 9);  // search full 9-ply for tic-tac-toe\n\nvoid setup() {\n  Serial.begin(9600);\n  Serial.println(\"Tic-Tac-Toe AI ready. You are O. Enter 1-9 to place O:\");\n  printBoard();\n}\n\nvoid loop() {\n  if (game.isGameOver()) {\n    // Announce result\n    if (game.isWinner(1)) Serial.println(\"AI wins!\");\n    else if (game.isWinner(2)) Serial.println(\"You win!\");\n    else Serial.println(\"It's a draw.\");\n    while(true); // halt\n  }\n  if (game.current == HUMAN) {\n    // Wait for human move via serial\n    if (Serial.available()) {\n      char c = Serial.read();\n      if (c &gt;= '1' &amp;&amp; c &lt;= '9') {\n        uint8_t pos = c - '1';  // convert char to 0-8 index\n        Move m = { pos, pos };\n        if (game.board[pos] == 0) {\n          game.applyMove(m);\n          printBoard();\n        } else {\n          Serial.println(\"Cell occupied, try again:\");\n        }\n      }\n    }\n  } else { // AI's turn\n    Move aiMove = ai.findBestMove();\n    Serial.print(\"AI plays at position \");\n    Serial.println(aiMove.to + 1);\n    game.applyMove(aiMove);\n    printBoard();\n  }\n}\n\n// Helper to print the board nicely\nvoid printBoard() {\n  const char symbols[3] = { ' ', 'X', 'O' };\n  Serial.println(\"Board:\");\n  for (int i = 0; i &lt; 9; i++) {\n    Serial.print(symbols[ game.board[i] ]);\n    if ((i % 3) == 2) Serial.println();\n    else Serial.print(\"|\");\n  }\n  Serial.println(\"-----\");\n}\n\n```\n\nThis sketch sets up the Serial communication, prints the board, and enters a loop where it waits for the human\u2019s input and responds with the AI\u2019s move. The `printBoard()` function shows X, O, or blank in a 3x3 grid format. We keep reading human moves until the game is over, then report the outcome.\n\n_Output Example:_ (User input in quotes)\n\n```\nTic-Tac-Toe AI ready. You are O. Enter 1-9 to place O:\nBoard:\n | | \n | | \n | | \n-----\nHuman: \"5\"\nBoard:\n | | \n |O| \n | | \n-----\nAI plays at position 1\nBoard:\nX| | \n |O| \n | | \n-----\nHuman: \"1\"\nBoard:\nO| | \n |O| \n | | \n-----\nAI plays at position 9\nBoard:\nO| | \n |O| \n | |X\n-----\n...\n\n```\n\nAnd so on, until the game ends.\n\nThis demonstrates a complete use-case of the library. The **library code (MinimaxAI)** plus the **game class and sketch** together realize a fully functional Tic-Tac-Toe AI on Arduino, with all moves via Serial.",
  "author_fullname": "t2_adfkq",
  "saved": false,
  "mod_reason_title": null,
  "gilded": 0,
  "clicked": false,
  "title": "The Amazing Minimax Algorithm (and Why You Should Use It in Your Games!) Pt 3",
  "link_flair_richtext": [
    {
      "e": "text",
      "t": "Algorithms"
    }
  ],
  "subreddit_name_prefixed": "r/ripred",
  "hidden": false,
  "pwls": null,
  "link_flair_css_class": "",
  "downs": 0,
  "thumbnail_height": null,
  "top_awarded_type": null,
  "hide_score": false,
  "name": "t3_1ihldvz",
  "quarantine": false,
  "link_flair_text_color": "light",
  "upvote_ratio": 0.75,
  "author_flair_background_color": "transparent",
  "subreddit_type": "public",
  "ups": 2,
  "total_awards_received": 0,
  "media_embed": {},
  "thumbnail_width": null,
  "author_flair_template_id": "9fa2ceaa-053c-11ed-bb97-124dff5ea4b4",
  "is_original_content": false,
  "user_reports": [],
  "secure_media": null,
  "is_reddit_media_domain": false,
  "is_meta": false,
  "category": null,
  "secure_media_embed": {},
  "link_flair_text": "Algorithms",
  "can_mod_post": false,
  "score": 2,
  "approved_by": null,
  "is_created_from_ads_ui": false,
  "author_premium": false,
  "thumbnail": "self",
  "edited": false,
  "author_flair_css_class": null,
  "author_flair_richtext": [
    {
      "a": ":snoo_facepalm:",
      "e": "emoji",
      "u": "https://emoji.redditmedia.com/wzxf63qpaezz_t5_3nqvj/snoo_facepalm"
    }
  ],
  "gildings": {},
  "content_categories": null,
  "is_self": true,
  "mod_note": null,
  "created": 1738685867.0,
  "link_flair_type": "richtext",
  "wls": null,
  "removed_by_category": null,
  "banned_by": null,
  "author_flair_type": "richtext",
  "domain": "self.ripred",
  "allow_live_comments": false,
  "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;h2&gt;Example: Tic-Tac-Toe AI Implementation&lt;/h2&gt;\n\n&lt;p&gt;To illustrate the library in action, we present a simplified Tic-Tac-Toe AI that uses our minimax library. This example will also serve as a template for other games.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Game Setup:&lt;/strong&gt; Tic-Tac-Toe is a 3x3 grid game where players alternate placing their symbol (X or O). We\u2019ll assume the AI plays \u201cX\u201d and the human \u201cO\u201d for evaluation purposes (it doesn&amp;#39;t actually matter which is which as long as evaluation is consistent). The entire game tree has at most 9! = 362880 possible games, but we can search it exhaustively easily. We will still use alpha-beta for demonstration, though it\u2019s actually not needed to solve tic-tac-toe (the state space is small). Our AI will always either win or draw, as tic-tac-toe is a solved game where a perfect player never loses.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;TicTacToeGame Class:&lt;/strong&gt; (As partially shown earlier)&lt;/p&gt;\n\n&lt;p&gt;```cpp&lt;/p&gt;\n\n&lt;h1&gt;include &amp;lt;MinimaxAI.h&amp;gt;&lt;/h1&gt;\n\n&lt;p&gt;enum Player { HUMAN = 0, AI = 1 };&lt;/p&gt;\n\n&lt;p&gt;class TicTacToeGame : public GameInterface {\npublic:\n    uint8_t board[9];\n    Player current;\n    TicTacToeGame() {\n        memset(board, 0, 9);\n        current = AI;  // let AI go first for example\n    }\n    // Evaluate board from AI&amp;#39;s perspective\n    int evaluateBoard() override {\n        if (isWinner(1)) return +10;       // AI (X) wins\n        if (isWinner(2)) return -10;       // Human (O) wins\n        return 0;  // draw or non-final state (could add heuristics here)\n    }\n    // Generate all possible moves (empty cells)\n    uint8_t generateMoves(Move *moves) override {\n        uint8_t count = 0;\n        for (uint8_t i = 0; i &amp;lt; 9; ++i) {\n            if (board[i] == 0) {           // 0 means empty\n                moves[count].from = i;     // &amp;#39;from&amp;#39; not used, but set to i for clarity\n                moves[count].to   = i;\n                count++;\n            }\n        }\n        return count;\n    }\n    // Apply move: place current player&amp;#39;s mark\n    void applyMove(const Move &amp;amp;m) override {\n        uint8_t pos = m.to;\n        board[pos] = (current == AI ? 1 : 2);\n        current    = (current == AI ? HUMAN : AI);\n    }\n    // Undo move: remove mark\n    void undoMove(const Move &amp;amp;m) override {\n        uint8_t pos = m.to;\n        board[pos] = 0;\n        current    = (current == AI ? HUMAN : AI);\n    }\n    bool isGameOver() override {\n        return isWinner(1) || isWinner(2) || isBoardFull();\n    }\n    int currentPlayer() override {\n        // Return +1 if it&amp;#39;s AI&amp;#39;s turn (maximizing), -1 if Human&amp;#39;s turn\n        return (current == AI ? 1 : -1);\n    }\nprivate:\n    bool isBoardFull() {\n        for (uint8_t i = 0; i &amp;lt; 9; ++i) {\n            if (board[i] == 0) return false;\n        }\n        return true;\n    }\n    bool isWinner(uint8_t mark) {\n        // Check all win conditions for mark (1 or 2)\n        const uint8_t wins[8][3] = {\n            {0,1,2}, {3,4,5}, {6,7,8},   // rows\n            {0,3,6}, {1,4,7}, {2,5,8},   // cols\n            {0,4,8}, {2,4,6}             // diagonals\n        };\n        for (auto &amp;amp;w : wins) {\n            if (board[w[0]] == mark &amp;amp;&amp;amp; board[w[1]] == mark &amp;amp;&amp;amp; board[w[2]] == mark)\n                return true;\n        }\n        return false;\n    }\n};&lt;/p&gt;\n\n&lt;p&gt;```&lt;/p&gt;\n\n&lt;p&gt;A few notes on this implementation:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;  We used &lt;code&gt;1&lt;/code&gt; to represent AI\u2019s mark (X) and &lt;code&gt;2&lt;/code&gt; for human (O). Initially, we set &lt;code&gt;current = AI&lt;/code&gt; (so AI goes first). This is just for demonstration; one could easily start with human first.&lt;/li&gt;\n&lt;li&gt;  The evaluation returns +10 for a win by AI, -10 for a win by the human, and 0 otherwise. This simplistic evaluation is sufficient because the search will go to terminal states (we set depth=9 so it can reach endgames). If we were limiting depth, we could add heuristic values for \u201ctwo in a row\u201d etc. to guide the AI.&lt;/li&gt;\n&lt;li&gt;  &lt;code&gt;generateMoves&lt;/code&gt; returns all empty positions. We don\u2019t do any special ordering here, but we could, for example, check if any move is a winning move and put it first (in tic-tac-toe, a simple heuristic: center (index 4) is often best to try first, corners next, edges last).&lt;/li&gt;\n&lt;li&gt;  &lt;code&gt;applyMove&lt;/code&gt; and &lt;code&gt;undoMove&lt;/code&gt; are straightforward. Because tic-tac-toe is so simple, we didn\u2019t need to store additional info for undo (the move itself knows the position, and we know what was there before \u2013 empty).&lt;/li&gt;\n&lt;li&gt;  &lt;code&gt;currentPlayer()&lt;/code&gt; returns +1 or -1 to indicate who\u2019s turn it is. In our &lt;code&gt;MinimaxAI&lt;/code&gt; implementation, we might not even need to call this if we manage a bool, but it\u2019s available for completeness or if the evaluation function needed to know whose turn (some games might incorporate whose turn it is into evaluation).&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;Minimax Solver Implementation:&lt;/strong&gt; With the game class defined, our solver can be implemented. Here\u2019s a conceptual snippet of how &lt;code&gt;MinimaxAI&lt;/code&gt; might look (non-templated version using interface pointers):&lt;/p&gt;\n\n&lt;p&gt;```cpp\nclass MinimaxAI {\npublic:\n    GameInterface *game;\n    uint8_t maxDepth;\n    Move bestMove;  // stores result of last search&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;MinimaxAI(GameInterface &amp;amp;gameRef, uint8_t depth)\n    : game(&amp;amp;gameRef), maxDepth(depth) {}\n\n// Public function to get best move\nMove findBestMove() {\n    // We assume game-&amp;gt;currentPlayer() tells us if this is maximizing player&amp;#39;s turn.\n    bool maximizing = (game-&amp;gt;currentPlayer() &amp;gt; 0);\n    int alpha = -32767;  // -INF\n    int beta  =  32767;  // +INF\n    bestMove = Move();   // reset\n    int bestVal = (maximizing ? -32767 : 32767);\n\n    Move moves[MAX_MOVES];\n    uint8_t moveCount = game-&amp;gt;generateMoves(moves);\n\n    for (uint8_t i = 0; i &amp;lt; moveCount; ++i) {\n        game-&amp;gt;applyMove(moves[i]);\n        int eval = minimaxRecursive(maxDepth - 1, alpha, beta, !maximizing);\n        game-&amp;gt;undoMove(moves[i]);\n\n        if (maximizing) {\n            if (eval &amp;gt; bestVal) {\n                bestVal = eval;\n                bestMove = moves[i];\n            }\n            alpha = max(alpha, eval);\n        } else {\n            if (eval &amp;lt; bestVal) {\n                bestVal = eval;\n                bestMove = moves[i];\n            }\n            beta = min(beta, eval);\n        }\n        if (alpha &amp;gt;= beta) {\n            // prune remaining moves at root (though rare to prune at root)\n            break;\n        }\n    }\n    return bestMove;\n}\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;private:\n    int minimaxRecursive(uint8_t depth, int alpha, int beta, bool maximizing) {\n        if (depth == 0 || game-&amp;gt;isGameOver()) {\n            return game-&amp;gt;evaluateBoard();\n        }\n        Move moves[MAX_MOVES];\n        uint8_t moveCount = game-&amp;gt;generateMoves(moves);\n        if (maximizing) {\n            int maxScore = -32767;\n            for (uint8_t i = 0; i &amp;lt; moveCount; ++i) {\n                game-&amp;gt;applyMove(moves[i]);\n                int score = minimaxRecursive(depth - 1, alpha, beta, false);\n                game-&amp;gt;undoMove(moves[i]);\n                if (score &amp;gt; maxScore) {\n                    maxScore = score;\n                }\n                if (score &amp;gt; alpha) {\n                    alpha = score;\n                }\n                if (alpha &amp;gt;= beta) break;  // cut-off\n            }\n            return maxScore;\n        } else {\n            int minScore = 32767;\n            for (uint8_t i = 0; i &amp;lt; moveCount; ++i) {\n                game-&amp;gt;applyMove(moves[i]);\n                int score = minimaxRecursive(depth - 1, alpha, beta, true);\n                game-&amp;gt;undoMove(moves[i]);\n                if (score &amp;lt; minScore) {\n                    minScore = score;\n                }\n                if (score &amp;lt; beta) {\n                    beta = score;\n                }\n                if (alpha &amp;gt;= beta) break;  // cut-off\n            }\n            return minScore;\n        }\n    }\n};&lt;/p&gt;\n\n&lt;p&gt;```&lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;(Note: In actual implementation, we would likely define &lt;code&gt;INF&lt;/code&gt; as a large sentinel value like &lt;code&gt;INT16_MAX&lt;/code&gt; since we use &lt;code&gt;int&lt;/code&gt; for scores, and ensure evaluateBoard never returns something beyond those bounds. Here 32767 is used as a stand-in for +\u221e.)&lt;/em&gt;&lt;/p&gt;\n\n&lt;p&gt;This code demonstrates the core logic:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;  &lt;code&gt;findBestMove()&lt;/code&gt; handles the top-level iteration over moves and chooses the best one.&lt;/li&gt;\n&lt;li&gt;  &lt;code&gt;minimaxRecursive()&lt;/code&gt; is the depth-first search with alpha-beta. It directly uses the game interface methods for moves and evaluation.&lt;/li&gt;\n&lt;li&gt;  We used &lt;code&gt;game-&amp;gt;currentPlayer()&lt;/code&gt; to decide if the root call is maximizing or not. In our tic-tac-toe game, that returns +1 if AI\u2019s turn (maximizing) or -1 if human\u2019s turn (minimizing). This ensures the algorithm\u2019s perspective aligns with the evaluation function\u2019s scoring (since &lt;code&gt;evaluateBoard&lt;/code&gt; was written from AI perspective, we must maximize on AI\u2019s turns).&lt;/li&gt;\n&lt;li&gt;  The algorithm updates &lt;code&gt;alpha&lt;/code&gt; and &lt;code&gt;beta&lt;/code&gt; appropriately and prunes when possible. Pruning at the root is rare because we want the best move even if others are worse, but the code still handles it.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;Example Sketch (&lt;code&gt;TicTacToeAI.ino&lt;/code&gt;):&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;Finally, here is how a simple loop might look in the Arduino sketch to play tic-tac-toe via Serial:&lt;/p&gt;\n\n&lt;p&gt;```cpp&lt;/p&gt;\n\n&lt;h1&gt;include &amp;lt;MinimaxAI.h&amp;gt;&lt;/h1&gt;\n\n&lt;p&gt;TicTacToeGame game;\nMinimaxAI ai(game, 9);  // search full 9-ply for tic-tac-toe&lt;/p&gt;\n\n&lt;p&gt;void setup() {\n  Serial.begin(9600);\n  Serial.println(&amp;quot;Tic-Tac-Toe AI ready. You are O. Enter 1-9 to place O:&amp;quot;);\n  printBoard();\n}&lt;/p&gt;\n\n&lt;p&gt;void loop() {\n  if (game.isGameOver()) {\n    // Announce result\n    if (game.isWinner(1)) Serial.println(&amp;quot;AI wins!&amp;quot;);\n    else if (game.isWinner(2)) Serial.println(&amp;quot;You win!&amp;quot;);\n    else Serial.println(&amp;quot;It&amp;#39;s a draw.&amp;quot;);\n    while(true); // halt\n  }\n  if (game.current == HUMAN) {\n    // Wait for human move via serial\n    if (Serial.available()) {\n      char c = Serial.read();\n      if (c &amp;gt;= &amp;#39;1&amp;#39; &amp;amp;&amp;amp; c &amp;lt;= &amp;#39;9&amp;#39;) {\n        uint8_t pos = c - &amp;#39;1&amp;#39;;  // convert char to 0-8 index\n        Move m = { pos, pos };\n        if (game.board[pos] == 0) {\n          game.applyMove(m);\n          printBoard();\n        } else {\n          Serial.println(&amp;quot;Cell occupied, try again:&amp;quot;);\n        }\n      }\n    }\n  } else { // AI&amp;#39;s turn\n    Move aiMove = ai.findBestMove();\n    Serial.print(&amp;quot;AI plays at position &amp;quot;);\n    Serial.println(aiMove.to + 1);\n    game.applyMove(aiMove);\n    printBoard();\n  }\n}&lt;/p&gt;\n\n&lt;p&gt;// Helper to print the board nicely\nvoid printBoard() {\n  const char symbols[3] = { &amp;#39; &amp;#39;, &amp;#39;X&amp;#39;, &amp;#39;O&amp;#39; };\n  Serial.println(&amp;quot;Board:&amp;quot;);\n  for (int i = 0; i &amp;lt; 9; i++) {\n    Serial.print(symbols[ game.board[i] ]);\n    if ((i % 3) == 2) Serial.println();\n    else Serial.print(&amp;quot;|&amp;quot;);\n  }\n  Serial.println(&amp;quot;-----&amp;quot;);\n}&lt;/p&gt;\n\n&lt;p&gt;```&lt;/p&gt;\n\n&lt;p&gt;This sketch sets up the Serial communication, prints the board, and enters a loop where it waits for the human\u2019s input and responds with the AI\u2019s move. The &lt;code&gt;printBoard()&lt;/code&gt; function shows X, O, or blank in a 3x3 grid format. We keep reading human moves until the game is over, then report the outcome.&lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;Output Example:&lt;/em&gt; (User input in quotes)&lt;/p&gt;\n\n&lt;p&gt;```\nTic-Tac-Toe AI ready. You are O. Enter 1-9 to place O:\nBoard:\n | | \n | | &lt;/p&gt;\n\n&lt;h2&gt; | | &lt;/h2&gt;\n\n&lt;p&gt;Human: &amp;quot;5&amp;quot;\nBoard:\n | | \n |O| &lt;/p&gt;\n\n&lt;h2&gt; | | &lt;/h2&gt;\n\n&lt;p&gt;AI plays at position 1\nBoard:\nX| | \n |O| &lt;/p&gt;\n\n&lt;h2&gt; | | &lt;/h2&gt;\n\n&lt;p&gt;Human: &amp;quot;1&amp;quot;\nBoard:\nO| | \n |O| &lt;/p&gt;\n\n&lt;h2&gt; | | &lt;/h2&gt;\n\n&lt;p&gt;AI plays at position 9\nBoard:\nO| | \n |O| &lt;/p&gt;\n\n&lt;h2&gt; | |X&lt;/h2&gt;\n\n&lt;p&gt;...&lt;/p&gt;\n\n&lt;p&gt;```&lt;/p&gt;\n\n&lt;p&gt;And so on, until the game ends.&lt;/p&gt;\n\n&lt;p&gt;This demonstrates a complete use-case of the library. The &lt;strong&gt;library code (MinimaxAI)&lt;/strong&gt; plus the &lt;strong&gt;game class and sketch&lt;/strong&gt; together realize a fully functional Tic-Tac-Toe AI on Arduino, with all moves via Serial.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
  "likes": null,
  "suggested_sort": null,
  "banned_at_utc": null,
  "view_count": null,
  "archived": false,
  "no_follow": false,
  "is_crosspostable": false,
  "pinned": false,
  "over_18": false,
  "all_awardings": [],
  "awarders": [],
  "media_only": false,
  "link_flair_template_id": "fe7a45c6-163e-11ed-bf29-7e0b698a7bb7",
  "can_gild": false,
  "spoiler": false,
  "locked": false,
  "author_flair_text": ":snoo_facepalm:",
  "treatment_tags": [],
  "visited": false,
  "removed_by": null,
  "num_reports": null,
  "distinguished": null,
  "subreddit_id": "t5_6as6rv",
  "author_is_blocked": false,
  "mod_reason_by": null,
  "removal_reason": null,
  "link_flair_background_color": "#7193ff",
  "id": "1ihldvz",
  "is_robot_indexable": true,
  "report_reasons": null,
  "author": "ripred3",
  "discussion_type": null,
  "num_comments": 0,
  "send_replies": true,
  "contest_mode": false,
  "mod_reports": [],
  "author_patreon_flair": false,
  "author_flair_text_color": "dark",
  "permalink": "/r/ripred/comments/1ihldvz/the_amazing_minimax_algorithm_and_why_you_should/",
  "stickied": false,
  "url": "https://www.reddit.com/r/ripred/comments/1ihldvz/the_amazing_minimax_algorithm_and_why_you_should/",
  "subreddit_subscribers": 43,
  "created_utc": 1738685867.0,
  "num_crossposts": 1,
  "media": null,
  "is_video": false
}